{
  "name": "Machine Learning project",
  "tagline": "",
  "body": "# Machine Learning project submission by MK\r\n\r\n## Goal\r\nThe purpose of this project is to prepare a machine learning algorithm that will be able to predict what kind of exercise is done based on data \r\ngathered from accelerometers on the belt, forearm, arm, and dumbell.\r\nThe data comes from the Human Activity Recognition study:\r\nUgulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. \"Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements\".\r\nMore information along with the source can be found here: \r\nhttp://groupware.les.inf.puc-rio.br/har\r\n\r\n## Model prepared\r\n-Model was calculated in R using mainly Caret package.\r\n-The data was divided into 60% for the training partition, and 40% for the testing one\r\nThe following steps were taken:\r\n  1. The data was filtered to leave only variables describing accelerators (except the outcome variable).\r\n  2. The summarized data was analyzed.\r\n```\r\n>summary(training)\r\n```\r\n   ![](http://imagizer.imageshack.us/v2/xq90/924/nEVm1W.png)\r\n```\r\nM<-abs(cor(training_sd[,-17]))\r\ndiag(M)<-0\r\nwhich(M>0.8,arr.ind=TRUE)\r\n```\r\n   ![](http://imagizer.imageshack.us/v2/xq90/922/P1svIV.png)\r\n   \r\n    Three things were noted: \r\n    - For variables ‘var_total_accel_belt’, ‘var_accel_arm’, ‘var_accel_dumbbell’, ‘var_accel_forearm’ very high number of values are missing. \r\n    - For variables \"accel_belt_x\",\"accel_belt_z\", \"accel_arm_x\", \"accel_arm_y\",\"accel_arm_z\", \"accel_dumbbell_x\",\"accel_dumbbell_z\",  \"accel_forearm_x\",  \"accel_forearm_z\"\r\n    standard deviation relatively higher than mean.\r\n    - Variables \"total_accel_belt\", \"accel_belt_y\" and \"accel_belt_z\" are correlated with each other.\r\n  Based on the above:\r\n  3. Variables with high number of NA were excluded from data set. This way the bias was reduced.\r\n  4. All the variables in data set were standarized. This way variance of the model was reduced.\r\n  5. Two principal components were calculated based on three correlated variables, and replaced them in the data set. This would simplify calculations and improve accuracy.\r\n  6. Several models relatively easy to compute were tried - i.e. linear discriminant analysis, CART and bagged CART.\r\nBagged CART turned out to have the best accuracy while cross validated on the testing set - it was 0.9003.\r\n```\r\n> modFit_treebag\r\nBagged CART \r\n\r\n11776 samples\r\n   15 predictor\r\n    5 classes: 'A', 'B', 'C', 'D', 'E' \r\n\r\nNo pre-processing\r\nResampling: Bootstrapped (25 reps) \r\nSummary of sample sizes: 11776, 11776, 11776, 11776, 11776, 11776, ... \r\nResampling results\r\n\r\n  Accuracy   Kappa      Accuracy SD  Kappa SD   \r\n  0.8762355  0.8433116  0.005550699  0.007022629\r\n```\r\nThe out-of-sample error was measured by percentage of predictions were incorrect on the testing sample. This value was ~10%.\r\n```> print(sum(pred_treebag!=testPC$classe)/length(testPC$classe))\r\n[1] 0.09966862\r\n```",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}